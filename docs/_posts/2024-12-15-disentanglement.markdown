---
layout:     post
title:      "Disentangling Disentanglement: how VAEs learn Independent Components"
date:       2024-12-15 21:39:00 +0100
author:     Carl Allen
paper-link: https://arxiv.org/pdf/2410.22559
link-text:  "[arXiv]"
categories: Theory

---

{% include_relative _includes/head.html %}

<table>
  <tr>
    <th>This post summarises <a href="https://arxiv.org/pdf/2410.22559">Unpicking Data at the Seams: VAEs, Disentanglement and Independent Components (Allen, 2024)</a>, which explains <b>why disentanglement arises in generative latent variable models</b>. </th>
  </tr>
</table>

**Disentanglement** is an intriguing phenomenon observed in generative latent variable models, such as [_Variational Autoencoders_ (VAEs)][VAE] (our focus), [Generative Adversarial Networks (GANs)](https://arxiv.org/pdf/1406.2661) and [latent Diffusion models](https://openaccess.thecvf.com/content/CVPR2022/papers/Rombach_High-Resolution_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2022_paper.pdf). Although disentanglement has not been rigorously defined, it refers to when semantically meaningful factors of the data map to distinct dimensions in latent space. This allows, for example, images to be generated that vary by a particular feature by changing a *single* latent dimension (Figure 1 (left), or [this video on disentanglement in GANs](https://www.youtube.com/watch?v=DbQNKdtoqUw)). It also allows apparent "embedding arithmetic", e.g. the vector difference between embeddings of two images that vary in style can be added to that of a third image to transform its style (Figure 1, right).

While disentanglement is often associated with particular model families whose popularity may ebb and flow (e.g. VAEs, $\beta$-VAEs, GANs), we show that the phenomenon itself **relates to the latent structure of the data** and is more fundamental than any model that may expose it.

<br>
<style>
#left {
   width: 75%;
    float:left;
}

#rightAside {
    width: 25%;
    float:right;
}
</style>

<p align="center">
  <div id="left">
    <img src="/assets/disentanglement/faces2.png" 
                    alt="faces" 
                    width="490" 
                    height="70"/>
            <img src="/assets/disentanglement/numbers.png" 
                    alt="numbers" 
                    width="493" 
                    height="70"/>
            <img src="/assets/disentanglement/frogs.png" 
                    alt="frogs" 
                    width="490" 
                    height="70"/>
  </div>
  <div id="rightAside">
            <img src="/assets/disentanglement/diffusion_church.png" 
                  alt="frogs" 
                  width="180" 
                  height="210"/>
  </div>
</p>
<p align="center">
    <small>Figure 1. Illustrating disentanglement: <emph>(left)</emph> Each row of images varies by a single semantic feature, e.g. hair style or orientation. Disentanglement means that (i) such images can be generated by varying a _single_ latent dimension, i.e. by traversing the latent space in "axis-aligned" directions (parallel to standard basis vectors); and (ii) each latent variable affects a distinct semantic feature rather than several or all. <emph>(right)</emph> Changing the style of an image in diffusion models by disentangled features. (Images from <a href="[url](https://arxiv.org/pdf/2002.03754)">Voynov & Babenko (2020)</a> and <a href="[url](https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Uncovering_the_Disentanglement_Capability_in_Text-to-Image_Diffusion_Models_CVPR_2023_paper.pdf)">Wu et al. (2023))</a></small>
</p>


$$\bullet$$ **Motivation**: Disentanglement is particularly intriguing because models such as VAEs are not intentionally designed to achieve it, and it even occurs in settings impossible for other methods (i.e. isotropic Gaussian prior).[^locatello]$$^,$$[^khemakem] Thus understanding disentanglement may provide new insights into how models learn and what is learnable. More broadly, the ability to separate out independent aspects of the data is relevant to many areas of machine learning, and teasing its generative factors apart may offer fundamental insights into the data itself. 

Machine learning has made incredible breakthroughs in recent years but our theoretical understanding lags notably behind, which may have serious implications as models increasingly reach the public sphere. Thus, a fundamental motivation for this work is to unravel some of the mystery of machine learning. We re-emphasise that disentanglement is not a model feature, rather a property of the data that a model may or may not expose and so is of more general interest. That said, autoencoding the data is often the first step in latent diffusion models, so understanding the latent space is relevant to current state of the art models.

$$\bullet$$ **Approach**: Recent works suggest that disentanglement arises in VAEs because commonly used diagonal posterior covariance matrices promote column-orthogonality in the decoder's Jacobian.[^rolinek]$$^,$$[^kumarpoole] In empirical support, columns of the decoder Jacobian are indeed found to be closer to orthogonal in VAEs with diagonal covariance than those with full covariance or general auto-encoders;[^rolinek] and directly encouraging column-orthogonality with a constraint is shown to induce disentanglement.[^kumarpoole] 

Building on this, [Allen (2024)][paper]: (A) further clarifies the connection between diagonal covariance and Jacobian orthogonality and (B) explains how disentanglement follows, showing that it amounts to **factorising the data distribution into *statistically independent components***.



<table>
  <tr>
    <th>$$
        \begin{equation}
        \text{diag. posterior covariance} 
            \quad  \overset{A}{\Rightarrow}\quad   \text{column-orthog. Jacobian} 
            \quad \overset{B}{\Rightarrow}\quad    \text{disentanglement}
        \end{equation}
        $$
 </th>
  </tr>
</table>


$$\bullet$$ **Problem set-up**: As in a VAE (or GAN), we assume that data $$x\in\mathcal{X} \subseteq\mathbb{R}^n$$ are generated by a latent variable model: independent latent variables are sampled $$z\in\mathcal{Z} =\mathbb{R}^m$$, $$p(z) = \prod_ip(z_i)$$, and <abbr title="A deterministic GAN generator can be thought of the limiting case as Var[x|z] tends to 0.">mapped stochastically to the data space by sampling $$x\sim p(x\mid z)$$</abbr>. The latent prior is commonly assumed to be isotropically Gaussian $$p_\theta(z_i) = \mathcal{N}(z_i,0,1)$$. We also assume $$p(x\mid z)$$ is Gaussian.
[Notation: unsubscripted probability distributions denote the ground truth; subscripts indicate modelled distribution.]


---

**TL;DR**: 
1. Disentanglement provably occurs in the _linear_ case, $$p_\theta(x\mid z) = \mathcal{N}(x; Dz,\sigma^2I),\ D\in\mathbb{R}^{n\times m}$$, corresponding to [probabilistic PCA (PPCA)][PPCA]. Of the infinite set of known solutions, a VAE with diagonal posterior covariance finds only those in which latent dimensions $$z_i$$ map to independent factors of variation in the data distribution, i.e. where $$p(x)$$ is  _disentangled_.
2. Somewhat surprisingly, the rationale for the linear case (described later in this post) extends to non-linear VAEs with diagonal posterior covariance. The latter property encourages columns of the decoder's Jacobian to be (approximately) orthogonal, which in turn means independent latent variables $$z_i$$ pass through the decoder and emerge (in $$\mathcal{X}$$) as statistically independent components that factorise the full push-forward distrubtion over the decoder-defined manifold.
   * i.e. diagonal covariances cause the decoder to map independent factors in the latent space to independent components in the data space.
3. A VAE's objective is maximised if the model distribution matches that of the data, hence if the data distribution factorises into independent components then the model distribution must similarly factorise. But, from 2, independent factors of the model (approximately) align with latent variables $$z_i$$ and so independent factors of $$p(x)$$ map through to distinct latent variables of the model, i.e. $$p(x)$$ is _disentangled_.

---
---
<br>

<table>
  <tr>
    <th>$$
    \begin{equation}
    \text{diag. posterior covariance} 
        \quad  \overset{A}{\Rightarrow}\quad   \text{column-orthog. Jacobian} 
        \color{lightgray}{\quad \overset{B}{\Rightarrow}\quad    \text{disentanglement}}
    \end{equation}
    $$
 </th>
  </tr>
</table>

### (A) From Diagonal Covariance to Jacobian Orthogonality

The VAE fits a latent variable model $$p_\theta(x) =\int_z p_\theta(x\mid z)p(z)$$ to  the data distribution $$p(x)$$ by maximising the Evidence Lower Bound (ELBO),

$$\ell(\theta, \phi) \quad =\quad \int p(x) \int q_\phi(z\mid x) 
\ \{\ \log p_\theta(x\mid z) \,-\, \beta \log \tfrac{q_\phi(z\mid x)}{p(z)} \ \}\ dz dx\ ,$$

where the ELBO has $$\beta=1$$ and [$$\beta>1$$ is found to improve disentanglement][betaVAE]. We assume common VAE assumptions:
* $$p_\theta(x\mid z) =\mathcal{N}(x;\,d(x),\sigma^2)\quad$$ with *decoder* $$d\in\mathcal{C}^2$$ (injective) and fixed variance $$\sigma^2$$;
* $$q_\phi(z\mid x)=\mathcal{N}(z;\,e(x),\Sigma_x)\quad$$ with *encoder* $$e$$ and learned variance $$\Sigma_x$$; and
* $$p(z)\quad\ \ \ =\mathcal{N}(z;\,0,I)\quad$$ where $$z_i$$ are *independent* with $$p(z_i)=\mathcal{N}(z_i;0,1)$$.

> **Maximising the ELBO = _maximum-likelihood$$^{++}$$_**:  Maximising the likelihood $$\int p(x)\log p_\theta(x)$$ minimises the KL divergence between the data and model distributions, but this is often intractable for a latent variable model. Maximising the ELBO minimises the KL divergences between $$p(x)q_\phi(z\mid x)$$ *and* $$p_\theta(x)p_\theta(z\mid x)\doteq p_\theta(x\mid z)p(z)$$, aligning two models of the joint distribution.
> Note:
> * the VAE decoder $$d$$ maps latent variables $$z\in\mathcal{Z}$$ to means $$\mu_z=\mathbb{E}[x\mid z]\in \mathcal{X}$$
> * if $$J_z$$ denotes $$d$$'s Jacobian evaluated at $$z$$, then $$J_{i,j} = \tfrac{\partial d(z)_i}{\partial z_j}$$ defines how a perturbation in the latent space (in direction $$z_j$$) translates to variation in the data space (in direction $$x_i$$).

The optimal $$\Sigma_x$$ is defined by the Hessian of $$\log p_\theta(x\mid z)$$ ([Opper & Archambeau](http://www0.cs.ucl.ac.uk/staff/c.archambeau/publ/neco_mo09_web.pdf)), meaning that if the decoder's second derivatives are small almost everywhere, e.g. as in a ReLU network [(see Abhishek & Kumar, 2020)](https://arxiv.org/pdf/2002.00041), we have:

$$
\begin{equation}
  \Sigma_x 
    \ \ \overset{O\&A}{=}\ \ I - \mathbb{E}_{q(z\mid x)}[\tfrac{\partial^2\log p_\theta(x\mid z)}{\partial z_i\partial z_j}]
    \ \ \approx\ \ I + \mathbb{E}_{q(z\mid x)}[\tfrac{1}{\beta\sigma^2}J_z^\top J_z]\ ,
  \tag{1}\label{eq:one}
\end{equation}
$$

and  for diagonal $$\Sigma_x$$, the ELBO is maximised when **columns of $$J_z$$ are approximately orthogonal**, $$\forall z$$ (as previously suggested[^rolinek]$$^,$$[^kumarpoole]). But if $$J_z=U_zS_zV_z^\top$$ is the singular value decomposition (SVD), $J_z$ is column-orthgonal _iff_ $$J_x^\top J_x = V_xS_x^2J_x^\top$$ is diagonal _iff_ $$V_z=I$$, i.e. when variation in latent component $$z_i$$ corresponds to a variation in data space in direction $$\mathbf{u}_i$$, the $$i^{th}$$ left singular vector of $$J_z$$ (column $$i$$ of $$U_z$$), with no effect in any other $$\mathbf{u}_{j\ne i}$$.


> **Take-away**: the ELBO is maximised if approximate posterior covariances match true posterior covariances, which can be expressed in terms of derivatives of $$p_\theta(x\mid z)$$. Diagonal posterior covariance does not imply that the Hessian is necessarily orthogonal, but if multiple solutions exist, the VAE prefers those where the Hessian is diagonal and so columns of the Jacobian are ($\approx$) orthogonal.
<!-- (hinting towards learning independent factors). -->

---
---
<br>

<table>
  <tr>
    <th>$$
      \begin{equation}
      {\color{lightgray}{\text{diag. posterior covariance} 
          \quad  \overset{A}{\Rightarrow}}}\quad   \text{column-orthog. Jacobian}
          \quad \overset{B}{\Rightarrow}\quad    \text{disentanglement}
      \end{equation}
      $$
 </th>
  </tr>
</table>


### (B) From Orthogonality to Statistical Independence

Understanding that diagonal posterior covariance promotes column-orthogonality in the decoder Jacobian, the question then is how does that _geometric_ property leads to the _statistical_ property of disentanglement. For that we consider the *push-forward* distribution defined by the decoder, supported over a $$m$$-dimensional manifold $$\mathcal{M}_d\subseteq\mathcal{X}$$. 

> A **push-forward distribution** describes the probability distribution of the output of a deterministic function given an input distribution. A VAE decoder maps samples of the latent prior $$p(z)$$ to the data space, where it defines a manifold $$\mathcal{M}_d$$ and push-forward distribution over it. 

---

#### Linear Case

For intuition, we first consider the linear case $$x=d(z)=Dz$$,  $$D\in\mathbb{R}^{n\times m}$$, the model considered in [Probabilistic PCA (PPCA)][PPCA], which has a tractable MLE solution and known optimal posterior

$$
\begin{equation}
  p_\theta(z\mid x) = \mathcal{N}(z;\, \tfrac{1}{\sigma^2}M D^\top x,\, M) \quad\quad\quad M = (I + \tfrac{1}{\sigma^2}D^\top D)^{-1}
  \tag{2}\label{eq:two}
\end{equation}
$$

Since $D$ is the Jacobian of $d$, the latter expression is in fact a special case of \eqref{eq:one}. Hence if $$D=USV^\top$$ is the SVD, the ELBO is maximised when $$\Sigma_x=M,\ \forall x\in\mathcal{X}$$ and so, for diagonal $$\Sigma_x$$, when $$V=I$$. 

<p align="center">
  <img src="/assets/disentanglement/linear.png" 
          alt="linear2" 
          width="440" 
          height="190" 
          style="display: block; margin: 0 auto"  />
  <small>Figure 2. Illustration of linear decoder $d:\mathcal{X}\to\mathcal{Z}$. The latent Gaussian prior is mapped to a Gaussian distribution in the data space over a linear manifold. </small>
</p>


The aim now is to understand how independent dimensions $$z_i\in\mathcal{Z}$$, and the probability density over them, pass through the decoder. For a given point $$z^*\in \mathcal{Z}$$, let: 
* $$\mathcal{Z^{(i)}}\subset\mathcal{Z}$$ be lines passing through $$z^*$$ parallel to each standard basis vector $$e_i$$ (blue dashed lines in Fig. 2), and $$\mathcal{M}_D^{(i)}\subset\mathcal{M_d}$$  be their images under $$d$$ that follow $$D$$'s left singular vectors $$\mathbf{u}_i$$ (red dashed lines); and
* $$x^{(U)}=U^\top x=U^\top Dz^*$$  be $x$ in the basis defined by columns of $$U$$

Crucially, the Jacobian of the map from $$z$$ to $$x^{(U)}$$ is the _diagonal_ matrix $$S$$, i.e. $$\tfrac{\partial x^{(U)}_i}{\partial z_j} =\{s_i\doteq S_{i,i} \text{ if }i=j; 0 \text{ o/w}\}$$. It then follows that independent $$z_i$$ map to independent components $$x^{(U)}_i$$ since:
1. each $$x^{(U)}_i$$ varies only with a distinct $$z_i$$ by considering  $$\tfrac{\partial x^{(U)}_i}{\partial z_j}$$ and so are *independent*;
2. the push-forward of $$d$$ restricted to $$\mathcal{Z^{(i)}}$$ has density $$p(x^{(U)}_i) = s_i^{-1}p(z_i)$$ over $$\mathcal{M}_D^{(i)}$$; and
3. the full push-forward distribution is given by $$p(Dz) = \mid\!D\!\mid ^{-1}p(z) = \prod_i s_i^{-1}p(z_i) = \prod _ip(x^{(U)}_i)$$.

This shows that the push-forward distribution defined by the decoder factorises as a product of independent univariate distributions ($$p(x^{(U)}_i)$$), which each correspond to a distinct latent dimension $$z_i$$. Thus, if the data follows that generative process and so factorises (with factors determined by singular value decomposition of ground truth $$D$$), then the ELBO is maximised when independent factors of the model ($$x^{(U)}_i$$) align with those of the data and so p(x) is **disentangled** as a product of *independent components* that align with latent dimensions.

This may not seem a surprise in the linear case since it is known from the outset that the push-forward distribution is Gaussian and so factorises as a product of univariate Gaussians. However, neither that fact nor the linearity of $$d$$ was used at any stage.

<!-- From $$J_z =\tfrac{d x}{d z}=US, \tfrac{d x}{d u} = U$$, we have $$\tfrac{d u}{d z} =S$$, so $$\tfrac{\partial u_i}{\partial z_j} = \{s_i$$ if $$i= j$$, otherwise $$0\}$$ and each $$u_i$$ depends on a distinct independent r.v. so are *independent*.
2. restricting $$D$$ to $$z_i\in \mathcal{Z}^{(i)}$$ and so $$u_i\in\mathcal{M_D^{(i)}}$$, $$p(u_i)= s_i^{-1}p(z_i)$$ (defined over $$\mathcal{M_D^{(i)}}$$)
 -->

---

#### Non-linear Case with Diagonal Jacobian

<p align="center">
  <img src="/assets/disentanglement/non_linear.png" 
        alt="non_linear2" 
        width="420" 
        height="200" 
        style="display: block; margin: 0 auto"  />
  <small>Figure 3. Illustration of non-linear decoder $d:\mathcal{X}\to\mathcal{Z}$. The latent Gaussian prior is mapped to a push-forward distribution in the data space over a non-linear manifold. </small>
</p>


We now take an analogous approach for a general VAE ($$x=d(z)$$, $$d\in\mathcal{C}^2$$) _with column-orthogonal decoder Jacobian_. The Jacobian and its factors, $$J_z=U_zS_zV_z^\top$$, may now vary with $$z$$, however column-orthogonality restricts $$V_z=I,\ \forall z\in \mathcal{Z}$$ and $$U_z$$, $$S_z$$ are continuous w.r.t. $$z$$ (from $$d\in\mathcal{C}^2$$ and [Papadopoulo & Lourakis (2006)](https://inria.hal.science/inria-00072686/file/RR-3961.pdf)). 

As in the linear case, for any $$z^*\in \mathcal{Z}$$, we can define lines $$\mathcal{Z^{(i)}}\subset\mathcal{Z}$$ passing through $$z^*$$ parallel to the standard basis (blue dashed lines in Fig. 3), and their images under $$d$$, $$\mathcal{M}_d^{(i)}\subset\mathcal{M_d}$$, which are potentially curved sub-manifolds following (local) left singular vectors of $$J_{z^*}$$ (red dashed lines).

Considering $$x=d(z)$$ in the local $$U$$-basis (i.e. columns of $$U_z$$), denoted $$x^{(U)}=U_z^\top x$$, the Jacobian of the map from $$z$$ to $$U_z^\top x^{(U)}$$ is again _diagonal_ $$S_z$$. Hence independent $$z_i\in\mathcal{Z}$$ map to independent components $$x^{(U)}_i$$ as in the linear case:
1. $$\{x^{(U)}_i\}_i$$ are *independent* (by consideration of partial derivatives $$\tfrac{\partial x^{(U)}_i}{\partial z_j}$$);
2. the push-forward of $$d$$ restricted to $$\mathcal{Z^{(i)}}$$ has density $$p(x^{(U)}_i) = s_i^{-1}p(z_i)$$ over $$\mathcal{M}_d^{(i)}$$; and
3. the full push-forward satisfies $$p(d(z)) = \mid J_z\mid ^{-1}p(z) = \prod_i s_i^{-1}p(z_i) = \prod _ip(x^{(U)}_i)$$.

Thus, by the same argument as in the linear case, the distribution over the decoder manifold factorises as a product of independent univariate push-forward distributions ($$p(x^{(U)}_i)$$), each corresponding to a distinct latent dimension $$z_i$$. 

We can now put everything together:
* The ELBO is maximised if the model distribution fits the data distribution, so assuming that the data distribution has independent factors (by being generated under the considered model or otherwise) the model distribution must factorise similarly.
* From part A, diagonal covariance matrices encourage the decoder's Jacobian to be (approximately) column-orthgonal and, where so, the push-foward distribution over the model manifold factorises into components aligned with latent dimensions (from part B).
* Thus the ELBO is maximised if independent components of the data distribution align with those of the model and those of the model align with latent dimensions, thus the VAE **identifies independent components that factorise the data distribution and aligns them with latent dimensions**, defining **disentanglement**.
   * (Component identifiability requires uniqueness of those independent distributions, analogous to requiring unique singular values in the linear case).

> **Key insight**: the above result hinges on the SVD of the Jacobian $$J_z = U_zS_zV_z^\top$$. By differentiability of $$d$$, the bases defined by columns of $$U_z$$ and $$V_z$$, in $$\mathcal{X}$$ and $$\mathcal{Z}$$ respectively, are continuous in $$z$$ so basis vectors form continuous curves in each domain (these are linear in $$\mathcal{Z} when $$V_z=I$$). By definition of the SVD, traversing a submanifold in one domain corresponds to traversing a corresponding submanifold in the other. The mapping between $$x$$ considered in the $$U$$-basis and $$z$$ considered in the $$V$$ basis has diagonal Jacobian given by $$S_z$$, and so is separable and probability densities over submanifolds in $$\mathcal{Z}$$ map to their counterpart in $$\mathcal{X}$$. In other words, independent components in $$\mathcal{Z}$$ map to independent components in $$\mathcal{X}$$.

**Notes**:
* While we assumed $$d\in\mathcal{C^2}$$ above, the result holds for continuous $d$ that are differentiable almost everywhere, e.g. ReLU networks.
* We recommend reading [the full paper][paper] for further details, such as:
  * consideration of whether orthogonality is strictly _necessary_ for disentanglement (the argument above shows it is _sufficient_);
  * further consideration of model _identifiability_, i.e. up to what symmetries a VAE can identify ground truth generative factors; and
  * explanation of the role of $\beta$ in a [$\beta$-VAE][betaVAE], notably:
     * if $$p_\theta(x\mid z)$$ is of exponential family form then $$\beta$$ corresponds to Var$$_\theta[x\mid z]$$ (generalising $\sigma^2$ in the Gaussian case); and
     * $\beta$ acts a "glue" determining how close data points need to be (in Euclidean norm) for the model to treat them as "similar", i.e. for their representations to merge.

<!-- 
**Interpreting β in β-VAEs**

β-VAEs introduce a hyperparameter β that scales the KL divergence term in the ELBO. Empirical studies have shown that increasing β enhances disentanglement, often at the cost of reconstruction quality. The sources offer a novel interpretation of β, viewing it as a factor scaling the variance of the likelihood distribution.

Increasing β corresponds to increasing the variance of the likelihood, essentially making the model more uncertain about its reconstructions. This increased uncertainty leads to greater overlap between the posterior distributions of nearby data points. As the ELBO encourages Jacobian orthogonality in expectation over the posterior distributions, larger overlap implies that orthogonality constraints apply over a broader region in the latent space, promoting stronger disentanglement.

Conversely, decreasing β reduces the likelihood variance, mitigating the issue of "posterior collapse". This phenomenon occurs when the likelihood becomes overly expressive, directly modeling the data distribution and rendering the latent variables redundant. By reducing the likelihood variance, β < 1 constrains the model's flexibility, preventing it from learning a trivial solution. -->

---
---

### Final remarks

We hope this post provides clearer insight into (i) what disentanglement means and how diagonal covariances, a seemingly innocuous design choice motivated by computational efficiency, leads to it; (ii) how statistically independent components of the data form "seams" running through the data manifold, which a VAE tries to "unpick"; and (iii) how understanding may transfer surprisingly well from linear to non-linear models.

---

This work throws up many interesting questions, e.g.:
* if the VAE objective aims to disentangle, why is disentanglement not observed more reliably, e.g. as observed by [Locatello et al. (2019)](https://arxiv.org/pdf/1811.12359)?
* how does this finding fit with VAE extensions that enhance entanglement, such as [FactorVAE](https://arxiv.org/abs/1802.05983) and [TC-VAE](https://arxiv.org/abs/1802.04942)?
* can this be used to automatically identify independent factors in the latent space of other models, e.g. GANs and latent diffusion models?
* given this result is for continuous data domains, how does it translate to discrete data such as text?
* how does this insight translate to other modelling paradigms, such as supervised, semi-supervised and self-supervised learning?

If any of these or related questions are of interest and you would like to collaborate, please free to get in touch (by email, twitter or bluesky).

Lastly, we welcome any constructive feedback or discussion on this post on bluesky (@carl-allen.bsky.social - I will pin a link in my profile).

Thanks for reading!

[paper]: https://arxiv.org/pdf/2410.22559
[VAE]: https://arxiv.org/pdf/1312.6114v11
[betaVAE]: https://openreview.net/forum?id=Sy2fzU9gl
[PPCA]: https://academic.oup.com/jrsssb/article-abstract/61/3/611/7083217

[^rolinek]: [Variational Autoencoders Pursue PCA Directions (by Accident); Rolinek et al. (2019)](https://arxiv.org/pdf/1812.06775)
[^kumarpoole]: [On Implicit Regularization in β-VAEs; Kumar \& Poole (2020)](https://arxiv.org/pdf/2002.00041)
[^locatello]: [Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations; Locatello et al. (2019)](https://arxiv.org/pdf/1811.12359)
[^khemakem]: [Variational Autoencoders and Nonlinear ICA: A Unifying Framework; Khemakhem et al. (2020)](https://proceedings.mlr.press/v108/khemakhem20a/khemakhem20a.pdf)
