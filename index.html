
<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Carl Allen</title>
<meta name="generator" content="Jekyll v3.7.4" />
<meta property="og:title" content="Carl Allen" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="/" />
<meta property="og:url" content="/" />
<meta property="og:site_name" content="Carl Allen" />
<script type="application/ld+json">
{"@type":"WebSite","url":"/","name":"Carl Allen","headline":"Carl Allen","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="assets/main.css"><link type="application/atom+xml" rel="alternate" href="/feed.xml" title="Carl Allen" /></head>
<body>

<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <div class="home">

<h1 id="carl-allen">Carl Allen</h1> <br />

<p>I am in my first year as a postdoc in Machine Learning at the <a href="https://ai.ethz.ch/"> ETH AI Centre</a> in 
  <a href="https://inf.ethz.ch/"> ETH Zürich</a>. 
  I am interested in mathematically understanding how current machine learing methods work and ideally improving them. 
  Particular areas of interest include 
  representation learning (e.g. of words, knowledge graphs or networks), 
  semi-supervised learning (learning from labelled and unlabelled data), 
  self-supervised learning (learning structure within data) and 
  neuro-symbolic integration (combining (soft) statistical learning with (hard) logical rules).</p>

<p>In 2021, I completed a PhD in Machine Learning at <a href="https://www.ed.ac.uk/informatics"> University of Edinburgh</a>, 
  where I was a member of the  <a href="http://datascience.inf.ed.ac.uk/"> Centre for Doctoral Training in Data Science</a>. 
  My thesis, titled "Towards a Theoretical Understanding of Word and Relation Representation" was supervised by 
  <a href="https://homepages.inf.ed.ac.uk/thospeda/">Tim Hospedales</a> and 
  <a href="https://homepages.inf.ed.ac.uk/imurray2/bio.html">Iain Murray</a>.</p>

<h2 id="background">Background</h2>
<p>I moved into Artificial Intelligence/Machine Learning research after working for some time in 
  <a href="https://www.quora.com/Did-anyone-feel-like-what-the-hell-am-I-doing-with-my-life">finance in London</a>.
  I hold a BSc in Mathematics and Chemistry from the <a href="https://www.southampton.ac.uk/">University of Southampton</a>,
  an MSc in Mathematics and the Foundations of Computer Science (MFoCS) from the <a href="https://www.ox.ac.uk/">University of Oxford</a> and
  MScs in Artificial Intelligence and Data Science from the <a href="https://www.ed.ac.uk/">University of Edinburgh</a>.</p>

<h2 id="publications">Publications</h2>

<p><strong>A Probabilistic Model for Discriminative and Neuro-Symbolic Semi-Supervised Learning</strong>
  <a href="https://arxiv.org/abs/2006.05896">[arXiv]</a> <br />
<u>C Allen</u>, I Balažević, T Hospedales <br />
</p>


  <p><strong>Interpreting Knowledge Rraph Relation Representation from Word Embeddings</strong>
    <a href="https://arxiv.org/pdf/1909.11611">[arXiv]</a> <br />
  <u>C Allen</u>*, I Balažević*, T Hospedales;
  <em> International Conference on Learning Representations</em>, 2021 <br />
  </p>

  <p><strong>Multi-scale Attributed Embedding of Networks</strong>
    <a href="https://arxiv.org/abs/1909.13021">[arXiv]</a> <a href="https://github.com/benedekrozemberczki/MUSAE">[github]</a><br />
  B Rozemberczki, <u>C Allen</u>, R Sarkar;
  <em> Journal of Complex Networks</em>, 2021 <br />
  </p>


  <p><strong>What the Vec? Towards Probabilistically Grounded Embeddings</strong>
    <a href="https://arxiv.org/abs/1805.12164">[arXiv]</a><br />
  <u>C Allen</u>, I Balažević, T Hospedales;
  <em> Neural Information Processing Systems</em>, 2019 <br />
  </p>

  <p><strong>Multi-relational Poincaré Graph Embeddings</strong>
    <a href="https://arxiv.org/abs/1905.09791">[arXiv]</a> <a href="https://github.com/ibalazevic/multirelational-poincare">[github]</a><br />
  I Balažević, <u>C Allen</u>, T Hospedales;
  <em> Neural Information Processing Systems</em>, 2019 <br />
  </p>

  <p><strong>Analogies Explained: Towards Understanding Word Embeddings</strong>
    <a href="https://arxiv.org/abs/1901.09813">[arXiv]</a>
    <a href="https://carl-allen.github.io/nlp/2019/07/01/explaining-analogies-explained.html">[blog post]</a>
    <a href="/s1577741/assets/Analogies_Explained_slides_ICML.pdf">[slides]</a><br />
  <u>C Allen</u>, T Hospedales;
  <em> International Conference on Machine Learning</em>, 2019 <strong>(honorable mention)</strong><br />
  </p>

  <p><strong>TuckER: Tensor Factorization for Knowledge Graph Completion</strong>
    <a href="https://arxiv.org/abs/1901.09590">[arXiv]</a> <a href="https://github.com/ibalazevic/TuckER">[github]</a><br />
  I Balažević, <u>C Allen</u>, T Hospedales;
  <em> Empirical Methods in Natural Language Processing</em>, 2019 <strong>(oral)</strong> <br />
  </p>

  <p><strong>Hypernetwork Knowledge Graph Embeddings</strong>
    <a href="https://arxiv.org/abs/1808.07018">[arXiv]</a> <a href="https://github.com/ibalazevic/HypER">[github]</a><br />
  I Balažević, <u>C Allen</u>, T Hospedales;
  <em> International Conference on Artificial Neural Networks</em>, 2019 <strong>(oral)</strong> <br />
  </p>



<!--   <h2 id="contact">Contact</h2>  -->
<a class="u-email" href="mailto:carl.allen@ed.ac.uk">carl.allen@ai.ethz.ch</a>
  &nbsp|&nbsp
  <a href="https://carl-allen.github.io/">Blog </a>
  &nbsp|&nbsp
  Informatics Forum, 10 Crichton Street, Edinburgh, EH8 9AB</p>

</div>

      </div>
    </main>
</body>

</html>
